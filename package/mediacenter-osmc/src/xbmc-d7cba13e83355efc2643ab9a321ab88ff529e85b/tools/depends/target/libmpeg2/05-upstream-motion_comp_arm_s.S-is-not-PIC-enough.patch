Index: libmpeg2/motion_comp_arm_s.S
===================================================================
--- libmpeg2/motion_comp_arm_s.S	(revision 1205)
+++ libmpeg2/motion_comp_arm_s.S	(working copy)
@@ -29,9 +29,13 @@
 	pld [r1]
         stmfd sp!, {r4-r11, lr} @ R14 is also called LR
 	and r4, r1, #3
-	adr r5, MC_put_o_16_arm_align_jt
-	add r5, r5, r4, lsl #2
-	ldr pc, [r5]
+	ldrb r4, [pc, r4]
+	add pc, pc, r4, lsl #2
+	.byte (MC_put_o_16_arm_align0 - 0f)>>2
+	.byte (MC_put_o_16_arm_align1 - 0f)>>2
+	.byte (MC_put_o_16_arm_align2 - 0f)>>2
+	.byte (MC_put_o_16_arm_align3 - 0f)>>2
+0:
 
 MC_put_o_16_arm_align0:
 	ldmia r1, {r4-r7}
@@ -75,11 +79,6 @@
 1:	PROC(24)
 	bne 1b
         ldmfd sp!, {r4-r11, pc} @@ update PC with LR content.
-MC_put_o_16_arm_align_jt:
-	.word MC_put_o_16_arm_align0
-	.word MC_put_o_16_arm_align1
-	.word MC_put_o_16_arm_align2
-	.word MC_put_o_16_arm_align3
 
 @ ----------------------------------------------------------------
 	.align
@@ -89,9 +88,14 @@
 	pld [r1]
         stmfd sp!, {r4-r10, lr} @ R14 is also called LR
 	and r4, r1, #3
-	adr r5, MC_put_o_8_arm_align_jt
-	add r5, r5, r4, lsl #2
-	ldr pc, [r5]
+	ldrb r4, [pc, r4]
+	add pc, pc, r4, lsl #2
+	.byte (MC_put_o_8_arm_align0 - 0f)>>2
+	.byte (MC_put_o_8_arm_align1 - 0f)>>2
+	.byte (MC_put_o_8_arm_align2 - 0f)>>2
+	.byte (MC_put_o_8_arm_align3 - 0f)>>2
+0:
+
 MC_put_o_8_arm_align0:
 	ldmia r1, {r4-r5}
 	add r1, r1, r2
@@ -133,12 +137,6 @@
 	bne 1b
         ldmfd sp!, {r4-r10, pc} @@ update PC with LR content.
 
-MC_put_o_8_arm_align_jt:
-	.word MC_put_o_8_arm_align0
-	.word MC_put_o_8_arm_align1
-	.word MC_put_o_8_arm_align2
-	.word MC_put_o_8_arm_align3
-
 @ ----------------------------------------------------------------
 .macro	AVG_PW rW1, rW2
 	mov \rW2, \rW2, lsl #24
@@ -157,12 +155,17 @@
 	@@ void func(uint8_t * dest, const uint8_t * ref, int stride, int height)
 	pld [r1]
         stmfd sp!, {r4-r11,lr} @ R14 is also called LR
+	ldr r11, 0f
 	and r4, r1, #3
-	adr r5, MC_put_x_16_arm_align_jt
-	ldr r11, [r5]
 	mvn r12, r11
-	add r5, r5, r4, lsl #2
-	ldr pc, [r5, #4]
+	ldrb r4, [pc, r4]
+	add pc, pc, r4, lsl #2
+	.byte (MC_put_x_16_arm_align0 - 0f)>>2
+	.byte (MC_put_x_16_arm_align1 - 0f)>>2
+	.byte (MC_put_x_16_arm_align2 - 0f)>>2
+	.byte (MC_put_x_16_arm_align3 - 0f)>>2
+0:
+	  .word 0x01010101
 
 .macro	ADJ_ALIGN_QW shift, R0, R1, R2, R3, R4
 	mov \R0, \R0, lsr #(\shift)
@@ -235,12 +238,6 @@
 	add r0, r0, r2
 	bne 1b
         ldmfd sp!, {r4-r11,pc} @@ update PC with LR content.
-MC_put_x_16_arm_align_jt:
-	.word 0x01010101
-	.word MC_put_x_16_arm_align0
-	.word MC_put_x_16_arm_align1
-	.word MC_put_x_16_arm_align2
-	.word MC_put_x_16_arm_align3
 
 @ ----------------------------------------------------------------
 	.align
@@ -249,12 +246,17 @@
 	@@ void func(uint8_t * dest, const uint8_t * ref, int stride, int height)
 	pld [r1]
         stmfd sp!, {r4-r11,lr} @ R14 is also called LR
+	ldr r11, 0f
 	and r4, r1, #3
-	adr r5, MC_put_x_8_arm_align_jt
-	ldr r11, [r5]
 	mvn r12, r11
-	add r5, r5, r4, lsl #2
-	ldr pc, [r5, #4]
+	ldrb r4, [pc, r4]
+	add pc, pc, r4, lsl #2
+	.byte (MC_put_x_8_arm_align0 - 0f)>>2
+	.byte (MC_put_x_8_arm_align1 - 0f)>>2
+	.byte (MC_put_x_8_arm_align2 - 0f)>>2
+	.byte (MC_put_x_8_arm_align3 - 0f)>>2
+0:
+	  .word 0x01010101
 
 .macro	ADJ_ALIGN_DW shift, R0, R1, R2
 	mov \R0, \R0, lsr #(\shift)
@@ -315,9 +317,3 @@
 	add r0, r0, r2
 	bne 1b
         ldmfd sp!, {r4-r11,pc} @@ update PC with LR content.
-MC_put_x_8_arm_align_jt:
-	.word 0x01010101
-	.word MC_put_x_8_arm_align0
-	.word MC_put_x_8_arm_align1
-	.word MC_put_x_8_arm_align2
-	.word MC_put_x_8_arm_align3

